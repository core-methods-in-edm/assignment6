---
title: "He Zhang-Assignment 6"
author: "He Zhang"
date: "11/21/2017"
output: html_document
---
#package
```{r}
library(rpart)
```
#data
```{r}
#Upload the data sets MOOC1.csv and MOOC2.csv
M1 <- read.csv("MOOC1.csv", header = TRUE)

M2 <- read.csv("MOOC2.csv", header=TRUE)

```

#Decision tree
```{r}
#Using the rpart package generate a classification tree predicting certified from the other variables in the M1 data frame. Which variables should you use?

c.tree1 <- rpart(certified~grade+assignment, method="class", data=M1)

#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)

#Plot your tree

post(c.tree1, file = "tree1.ps", title = "MOOC") #This creates a pdf image of the tree

```

```{r}
c.tree2 <- prune(c.tree1, cp = 0.5)#Set cp to the level at which you want the tree to end

#Visualize this tree and compare it to the one you generated earlier

post(c.tree2, file = "tree2.ps", title = "MOOC") #This creates a pdf image of the tree
```

#Now use both the original tree and the pruned tree to make predictions about the the students in the second data set. Which tree has a lower error rate?

```{r}
M2$predict1 <- predict(c.tree1, M2, type = "class")

M2$predict2 <- predict(c.tree2, M2, type = "class")

confusion1<-table(M2$certified, M2$predict1)
matrix1 <- as.matrix(confusion1)
kappa(matrix1, exact = TRUE)/kappa(matrix1)

confusion2<-table(M2$certified, M2$predict2)
matrix2 <- as.matrix(confusion2)
kappa(matrix2, exact = TRUE)/kappa(matrix2)

#The Kappa value of c.tree1 is 0.97 and the kappa value of c.tree2 is 0.899, which means that the percentage of the result would happen by chance in the pruned tree is significantly lower than the first tree. Thus, the second tree has a lower error rate.
```