---
title: "HUDK4050 HW6-Kmeans Clustering & Principal Component Analysis"
author: "Xiyun Zhang"
date: "12/12/2020"
output: html_document
---

Data:
x: Back and Forth
y: Up and Down
z: Left and Right
Acceleration: Acceleration during the activity

Survey Questions:
Name: Name who participates in the activity
Gender: The person's gender: female or Male
Height: Personal Height in cm
Weight: Personal Weight in kg
Fitness: Overall fitness level on a scale of 1- 5: 1. Poor 2. Fair 3. Good 4. Very good 5. Excellent.
Favor: How much the person prefer jumping: 1 being do not like and 5 being like it very much.
Prior: If the person has prior experience of jumping rope or not: 1 being do not have much experience and 5 being have a lot of experience.
Illness: Level of illness that might effect the person during jumping rope: 0 being have no illness and 5 being strongly effect by the illness.
Happyness: Level of happiness before the person jumping rope: 1 being very sad and 5 being really happy.
time_interval: The time when the person did the activity: Morning (6 am - 12pm), Afternoon  (12pm - 4pm), Evening (4 pm - 10 pm), Night (10 pm - 6 am). 
last_meal: How long before jumping rope did the person have his/her last meal: 30mins-1 hour ago, 1 hour- 2 hours ago, more than 2 hours
num_jumps: Number of jumps the person accomplished in 1-minute.



```{r}
library(dplyr)
DF <- read.csv("Clean_data_H5.csv")
plot(DF$avg_x)
plot(DF$avg_y)
plot(DF$avg_z)
for(i in 1:nrow(DF)){
  if(DF$avg_z[i]>2.5){
    DF$avg_z[i] = DF$avg_z[i]-8
  }
}
DF$avg_y = abs(DF$avg_y)
DF = DF[,-1]
DF$Participant[DF$Participant=="Vidya Madhaban"] = "Vidya Madhavan"
DF = mutate(DF,gender = 1, height = 1, weight = 1, fitness = 1, favor = 1, prior = 1, illness = 1, happyness = 1, time_interval = 1, last_meal = 1, num_jumps = 1)
names(DF)[1] = "name"
```
Since there were some negative values in the initial clean data, the plots seemingly to be inefficient to produce any visualization at this point. Therefore, we decided to use the absolute value of these negtive ones to plot new diagrams. 


```{r}
plot(DF$avg_x)
plot(DF$avg_y)
plot(DF$avg_z)
```
It turns out that the plot of y variable to be much more efficient after using the absolute value. 
Based on the plots, we can tell that most of our data tend to be together with some outliers. 


```{r}
survey = read.csv("Jump Rope Research.csv")
survey1 = select(survey, name = Q1, gender = Q2, height = Q3, weight = Q4, fitness = Q5, favor = Q6, prior = Q7, illness = Q8, happyness = Q9, time_interval = Q10, last_meal = Q11, num_jumps = Q12)
survey1 = survey1[-c(1,2),]
```
```{r}
colname = colnames(DF)
colname = colname[-c(1:6)]
for(j in colname){
  for(i in 1:nrow(DF)){
    DF[[j]][i] = survey1[[j]][survey1$name == DF$name[i]]
  }
}
colname = c(7,10:16)
for(i in colname){DF[,i] = as.factor(DF[,i])}
colname1 = c(8,9,17)
for(i in colname1){DF[,i] = as.numeric(DF[,i])}
```

```{r}
DF = mutate(DF, time = rep(0:60,9))
```

```{r}
DF1 = select(DF, abs_acceleration,avg_y,avg_x,avg_z)
pairs(DF1)
```
In this plot, we will mainly focused on the regression between acceleration and xyz variables to see whether there is any relationship between acceleration and the predictor variables. 
From the plot, we can see that it is hardly to tell if there is any relationship between acceleration and the xyz variables that all the plots are in a cloud shape.


```{r}
cor(DF1)
```
The absolute value of correlation between acceleration and y is: 0.43044889 which stands for a moderate correlation.
The absolute value of correlation between acceleration and x is: 0.26456843 which shows a relatively weak correlation.
The absolute value of correlation between acceleration and z is: 0.009613775 which means that there is weak or no correlation between these two variables.


### K-means analysis
```{r}
#install.packages("stats")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("ggfortify")

library(stats)
library(dplyr)
library(ggplot2)
library(ggfortify)
str(DF)

DF2 <- select(DF,c(1,3:6,8:14,17))
str(DF2)
colname = c(8:12)
for(i in colname){DF2[,i] = as.numeric(levels(DF2[,i]))[DF2[,i]]}
str(DF2)


DF2 <- DF2 %>% group_by(name)%>%summarise(avg_x=mean(avg_x), avg_y=mean(avg_y),avg_z=mean(avg_z),abs_acceleration=mean(abs_acceleration),height = mean(height), weight = mean(weight), fitness = mean(fitness), favor = mean(favor), prior = mean(prior), illness = mean(illness), happyness = mean(happyness),  num_jumps = mean(num_jumps))

DF_kmeans <- scale(DF2[,-1])

```


```{r}
#install.packages("factoextra")
library(factoextra)
fviz_nbclust(DF_kmeans, kmeans, method = "wss",k.max=8) +
  geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")
```
The Optimal Numbers of Cluster indicates that we should use k = 4 for further analysis.


```{r}
# Compute k-means with k = 4
set.seed(8)
km4 <- kmeans(DF_kmeans, 4)
autoplot(km4,DF_kmeans,frame=T)+
  labs(title = "Kmeans Clustering with k = 4")+
  theme_bw()
```

Although the optimal numbers of clusters indicates we should have 4 clusters, the above plot doesn't give us as useful insights as we thought. It is hardly to separte our group member into two groups: novices and experts. So, we try to use 2-clusters instead.

```{r}
# Compute k-means with k = 2
set.seed(6)
km2 <- kmeans(DF_kmeans, 2)
autoplot(km2,DF_kmeans,frame=T) +
  geom_text(aes(label=DF2$name),hjust=0, vjust=0)+ 
  labs(title = "Kmeans Clustering with k = 2")+
  theme_bw()
  

print(km2)
DF2 <- data.frame(DF2, km2$cluster)

```

According to the k-means clustering, we are clustered into two group1: 
Group 1 (Novice): Vidya Madhavan, Paolo Rivas, Ruoyi Wang
Group 2 (Experienced): Qiyu Wu, Xiyun Zhang, Kaijie Fang, Hangshi Jin, Yifei Zhang, Wenning Xiao

We call Group 1 with smaller number of rope jumping and less prior experience Novice while Group 2 with higher number of rope jumping and more prior experience Experienced.

Given the cluster means, we can see Group 2 (Experienced) has lower absolute means in avg_x, avg_v, avg_z and abs_acceleration, and lower means in weight, fitness, illness and happyness. However, they has higher means in height, favor and prior.
 
Thus, we conclude:
1. Group 2 who show a preference for jumping rope and have prior experience can make more jumps in 1 minutes than Group 1. 
2. Experienced would move up, down, left and right in a small amplitude and small acceleration.
3. Lower illness level and higher happiness level might contribute being an expert in jumping ropes.
4. It is interested to see experts have lower fitness level than novices. 




### Principal Component Analysis
```{r}
pca <- prcomp(DF_kmeans, scale. = TRUE)
summary(pca)
plot(pca, type = "lines")
(loadings <- abs(pca$rotation))
#biplot(pca)
```

It can be seen from the summary that PC1 and PC2 contribute to 58.19% of the variation of the data while PC1, PC2, PC3 and PC4 contribute to 83.74% of the variation of the data.

PC1 has comparatively high loading scores for  height, weight, abs_acceleration, avg_x and prior.
PC2 has comparatively high loading scores for avg_y, fitness, favor, illness, happyness and num_jumps.

```{r}
#library(devtools)
#install_github("vqv/ggbiplot")
library(ggbiplot)
#ggbiplot(pca)+ylim(-2,2)+xlim(-2,2.5)
#ggbiplot(pca, labels=DF2$name)+ylim(-2,2)+xlim(-1.5,2.5)

pca_group <- c(rep("Group A", 3), rep("Group B",2), "Group A", rep("Group B",3))

ggbiplot(pca ,ellipse=TRUE, choices = c(1,2),  labels=DF2$name, groups=pca_group)+ylim(-2,2)+xlim(-1.5,2.5)+ labs(title = "PCA Analysis with PC1 and PC2")+ theme_bw()

```


Here, we can see that the variables height, weight, abs_acceleration and avg_x all contribute to PC1, with higher values in those variables moving the samples to the right on this plot. 

After specifying Group A and Group B, we find Group A form a distinct cluster to the right. Looking at the axes, we see that Group A are characterized by high values for height, weight, abs_acceleration and avg_x. Group B, on the other hand, are characterized by high values for prior, favor, and num_jumps and high absolute values for avg_y, illness, fitness and happyness.

Thus, we conclude:
1. The survey questions does not perfectly separate the group based on novices and experts that both novices and experts have some characteristics that are in the same cluster.
2. However, it is interesting to see that Vidya and Paolo are in the same cluster whom are both categorized as novices based on the K-mean. It might because they have some similarities.
2. Kaijie, Hangshi, Paolo, and Vidya are in group A are the taller ones and have higher average weight in our group. It might because of these facts that make them have higher absolute value of acceleration during the activity.
3. Xiyun, Yifei, Wenning, Qiyu, and Ruoyi are in group B. This group have an overall higher number of jumps. Based on the graph, we might conclude that with more prior experience with jumping ropes and more favor in doing this activity might lead to a higher number of jumps. 
4. Another interesting thing here is that though Ruoyi is categorized as a novice and based on the survey question, she jumped 73 times during 1-minuets, she has similar prior experience and favor with the others who are defined as experts. This means that she might be an outlier in the novices group.
5. Another thing that brings to an attention is that fitness has not been counted as a significant value in the PCA plot. 


```{r}
ggbiplot(pca ,ellipse=TRUE, choices = c(3,4), labels=DF2$name, groups=pca_group)+ylim(-2,2)+xlim(-1.5,2.5)+ labs(title = "PCA Analysis with PC3 and PC4")+ theme_bw()
```
We don't see much insights of Groups with PC3 and PC4 because they overlapped heavily.


